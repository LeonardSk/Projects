---
title: "TidyModels Playaround"
author: "Leonard Seok"
date: "24 May 2020"
output: 
  html_document:
    theme: journal
    hightlight: tango
---

Lets load the PimaIndiansDiabetes dataset for this play-around

```{r setup, results = 'hide'}
# A custom function to install and load packages
install.custom <- function(package.name) {
  if (!(package.name %in% rownames(installed.packages()))) {
    install.packages(package.name)
  } else {
    print(paste0(package.name," ","is already installed"))
  }
  library(package.name, character.only = T)
}

install.custom("purrr")
list_package <- list("mlbench", "dplyr", "tidyverse", "ggplot2", "parsnip")
map(list_package, ~install.custom(.x))

data("PimaIndiansDiabetes") # Load the data 

data <- PimaIndiansDiabetes
```

Investigate the Numeric data with some histograms

```{r}
data %>% dplyr::select_if(is.numeric) %>% 
  gather(key='field', value='value') %>%
  ggplot(aes(x=value)) + geom_histogram(color='black',fill='cyan') +
  facet_wrap(~field, scales = 'free')
```

We can see that for some fields such as insulin, pregnant, and pressure has a large concentration of 0. 
It doesn't quite makes sense that mass and tricep skin fold are recorded as 0, so they are most probably missing values.

```{r}
data %>% ggplot(aes(x=diabetes)) + geom_bar()
```

For all fields other than pregnant and diabetes, lets set 0 to be NA

```{r}
d1 <- data %>% select(-pregnant,-diabetes) %>% 
  map_dfr(~ifelse(.x==0,NA,.x))

d2 <- data %>% select(pregnant, diabetes) %>% 
  mutate(diabetes = as.factor(ifelse(diabetes=='pos',1,0)))

data_clean <- cbind(d1, d2)

data_clean %>% select_if(is.numeric) %>% 
  gather(key='key', value = 'value') %>% 
  ggplot(aes(x=value)) + geom_histogram(color='black', fill='cyan') +
  facet_wrap(~key, scales = 'free')
```

## Modelling with TidyModels

Splitting the data into train and test sets

```{r}
set.seed(101)

data_ttsplit <- rsample::initial_split(data_clean, prop=0.75)
train <- rsample::training(data_ttsplit)
test <- rsample::testing(data_ttsplit)
```

We will now create cross fold validation, so that we can tune the model parameters. Here we create a 10 fold cross val:

```{r}
data_cv <- rsample::vfold_cv(train, v=10)
```

Next we shall define the the formula (the response and the predictor variables), as well as any pre-processing steps required.
See here for more recipes https://recipes.tidymodels.org/articles/Custom_Steps.html

```{r}
recipe1 <- recipes::recipe(diabetes ~ ., data = train) %>% 
  recipes::step_normalize(recipes::all_numeric()) %>% 
  recipes::step_knnimpute(recipes::all_predictors()) # ?selection for other role sections

recipe1
```

We can extract the pre-processed dataset to view what it looks like, albeit it being unnessary when fitting

```{r}
train_pp <- recipe1 %>% recipes::prep(train) %>% 
  recipes::juice()
```

Hence we can see that our pre-processing has:

* Normalised the numeric data to have a mean of 0 and SD of 1
* imputed missing data using the K-Nearest Neighbour method

Lets create some model objects, note that this is still not actually fitting the model itself

```{r}
# Logistic model object
log_reg_mod <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

# Random Forest Object
rf_mod <- rand_forest() %>% 
  set_args(mtry=tune(), trees = tune()) %>% # mtry and tree are the parm that we have decide to tune 
  set_engine("ranger", importance = "impurity") %>% 
  set_mode("classification")
```

Now we put the recipe and the model object into a workflow

```{r}
rf_mod_wf <- workflows::workflow() %>% 
  workflows::add_recipe(recipe1) %>% 
  workflows::add_model(rf_mod)
```

Using this workflow and the Cross fold validation, we will tune the mtry and tree parm

```{r}
install.custom("yardstick")

rf_grid <- expand.grid(mtry=3:6, trees = c(200,300,500))

rf_tune_results <- rf_mod_wf %>% 
  tune::tune_grid(resamples = data_cv
            , grid = rf_grid
            , metrics = metric_set(accuracy, roc_auc))

rf_tune_results %>% 
  tune::show_best(metric = "accuracy") %>% 
  knitr::kable()

rf_tune_results %>% 
  tune::show_best(metric = "roc_auc") %>% 
  knitr::kable()

```

Based on both metrics, we can see that mtry = 4 and trees = 500 seem to be the best performing
We shall create a dataframe for the parameter that we will use for our final model

```{r}
parm_fin <- tibble(mtry = 4, trees = 500)

# and then we add it to our workflow

rf_mod_wf <- rf_mod_wf %>% finalize_workflow(parm_fin) 
rf_mod_wf

```

Now we can finally fit the model to our training, and then score it on the test.

```{r}
rf_fitted <- rf_mod_wf %>% last_fit(data_ttsplit)
```

We can then simply check the test set performance 

```{r}
rf_fitted %>% collect_metrics()
```

We can also generate predictions from the test set scoring 

```{r}
test_preds <- rf_fitted %>% collect_predictions()

# Subsequently, we can also generate a confusion metric
test_preds %>% yardstick::conf_mat(truth=diabetes, estimate=.pred_class)
```

We will now plot the ROC / Gini curve

```{r}
rf_roc <- test_preds %>% yardstick::roc_curve(truth=diabetes,estimate=.pred_1)

rf_roc %>% ggplot(aes(x=1-specificity, y=sensitivity)) + geom_path(color='red') +
  geom_abline(lty=3) +
  coord_equal()

# Obtaining the ROC - this should match with the collected metrics above
yardstick::roc_auc(test_preds, truth=diabetes, .pred_1)
```

We can also plot the probability distributions

```{r}
test_preds %>% ggplot(aes(x=.pred_1)) + geom_density(aes(fill=diabetes), alpha = 1/3)
```

Once we are happy with the test set performance, we can then train our model on the full dataset and predict on new data.

```{r}
rf_mod_FIN <- fit(rf_mod_wf, data_clean)
```

Say we define some new data

```{r}
new_dat <- tribble(~pregnant, ~glucose, ~pressure, ~triceps, ~insulin, ~mass, ~pedigree, ~age,
                     3, 51, 90, 21, 200, 13.3, 0.62, 50,
                     4, 80, 90, 40, 85, 50.5, 0.8, 26)

predict(rf_mod_FIN, new_data = new_dat, type = 'prob')
predict(rf_mod_FIN, new_data = new_dat, type = 'class')
```

We can see that both predictions are No diabetes.

# Next Steps

We shall continue this by trying an XGBoost and a usual log reg, and see how this compares to our RF model!
https://www.r-bloggers.com/using-xgboost-with-tidymodels/
